References
[1] Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Cheb-
otar, Omar Cortes, Byron David, Chelsea Finn, Chuyuan Fu,
Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog,
Daniel Ho, Jasmine Hsu, Julian Ibarz, Brian Ichter, Alex Ir-
pan, Eric Jang, Rosario Jauregui Ruano, Kyle Jeffrey, Sally
Jesmonth, Nikhil Joshi, Ryan Julian, Dmitry Kalashnikov,
Yuheng Kuang, Kuang-Huei Lee, Sergey Levine, Yao Lu,
Linda Luu, Carolina Parada, Peter Pastor, Jornell Quiambao,
Kanishka Rao, Jarek Rettinghouse, Diego Reyes, Pierre Ser-
manet, Nicolas Sievers, Clayton Tan, Alexander Toshev, Vin-
cent Vanhoucke, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu,
Mengyuan Yan, and Andy Zeng. Do as i can and not as i
say: Grounding language in robotic affordances. In arXiv
preprint arXiv:2204.01691, 2022. 2
[2] I. Armeni, Z. He, J. Gwak, A. Zamir, M. Fischer, J. Malik,
and S. Savarese. 3D scene graph: A structure for unified
semantics, 3D space, and camera. In Intl. Conf. on Computer
Vision (ICCV), pages 5664–5673, 2019. 1, 2
[3] Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol
Hausman, Alexander Herzog, Daniel Ho, Julian Ibarz, Alex
Irpan, Eric Jang, Ryan Julian, et al. Do as i can, not as i say:
Grounding language in robotic affordances. In Conference
on Robot Learning (CoRL), pages 287–318. PMLR, 2023. 2
[4] Junting Chen, G. Li, Suryansh Kumar, Bernard Ghanem,
and Fisher Yu.
How to not train your dragon: Training-
free embodied object goal navigation with semantic fron-
tiers. Robotics: Science and Systems (RSS), 2023. 2
[5] Y. Chen, J. Arkin, Y. Zhang, N.A. Roy, and C. Fan. Auto-
TAMP: Autoregressive task and motion planning with LLMs
as translators and checkers. In IEEE Intl. Conf. on Robotics
and Automation (ICRA), pages 6695–6702, 2023. 8
[6] Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas A. Roy,
and Chuchu Fan. Autotamp: Autoregressive task and mo-
tion planning with llms as translators and checkers. arXiv
preprintL 2306.06531, 2023. 3
[7] Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabi-
novich. SuperPoint: Self-Supervised Interest Point Detec-
tion and Description.
In IEEE Conf. on Computer Vision
and Pattern Recognition (CVPR), pages 337–349, 2018. 3
[8] D. Diaper and Neville A. Stanton. The Handbook of Task
Analysis for Human-Computer Interaction. Lawrence Erl-
baum, 2004. 3
[9] F. Dellaert et al.
Georgia Tech Smoothing And Mapping
(GTSAM). https://gtsam.org/, 2019. 3
[10] Caelan Reed Garrett, Rohan Chitnis, Rachel Holladay,
Beomjoon Kim, Tom Silver, Leslie Pack Kaelbling, and
Tomás Lozano-Pérez. Integrated task and motion planning.
Annual review of control, robotics, and autonomous systems,
4(1):265–293, 2021. 2
[11] Qiao Gu, Alihusein Kuwajerwala, Sacha Morin, Krishna
Murthy Jatavallabhula, Bipasha Sen, Aditya Agarwal, Cor-
ban Rivera, William Paul, Kirsty Ellis, Rama Chellappa,
Chuang Gan, Celso Miguel de Melo, Joshua B. Tenenbaum,
Antonio Torralba, Florian Shkurti, and Liam Paull.
Con-
ceptgraphs: Open-vocabulary 3d scene graphs for perception
and planning. IEEE Intl. Conf. on Robotics and Automation
(ICRA), 2024. 2
[12] Qiao Gu,
Alihusein Kuwajerwala,
Sacha Morin,
Kr-
ishna Murthy Jatavallabhula, Bipasha Sen, Aditya Agarwal,
Corban Rivera, William Paul, Kirsty Ellis, Rama Chellappa,
Chuang Gan, Celso Miguel de Melo, Joshua B. Tenenbaum,
Antonio Torralba, Florian Shkurti, and Liam Paull. Concept-
graphs: Open-vocabulary 3d scene graphs for perception and
planning. In IEEE Intl. Conf. on Robotics and Automation
(ICRA), 2024. 1, 2
[13] Yicong Hong, Qi Wu, Yuankai Qi, Cristian Rodriguez-
Opazo, and Stephen Gould. A recurrent vision-and-language
bert for navigation. In IEEE Conf. on Computer Vision and
Pattern Recognition (CVPR), 2021. 2
[14] N. Hughes, Y. Chang, and L. Carlone. Hydra: a real-time
spatial perception engine for 3D scene graph construction
and optimization. In Robotics: Science and Systems (RSS),
2022. 2, 7, 1
[15] N. Hughes, Y. Chang, S. Hu, R. Talak, R. Abdulhai, J.
Strader, and L. Carlone. Foundations of spatial perception
for robotics: Hierarchical representations and real-time sys-
tems. Intl. J. of Robotics Research, 2024. 1, 7, 2
[16] Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita
Orlov, and Humphrey Shi. OneFormer: One Transformer to
Rule Universal Image Segmentation. In IEEE Conf. on Com-
puter Vision and Pattern Recognition (CVPR), pages 2989–
2998, 2023. 7
[17] Krishna Murthy Jatavallabhula, Alihusein Kuwajerwala,
Qiao Gu, Mohd Omama, Tao Chen, Shuang Li, Ganesh Iyer,
Soroush Saryazdi, Nikhil Keetha, Ayush Tewari, Joshua B.
Tenenbaum, Celso Miguel de Melo, Madhava Krishna, Liam
Paull, Florian Shkurti, and Antonio Torralba. Conceptfusion:
Open-set multimodal 3d mapping. In Robotics: Science and
Systems (RSS), 2023. 1
[18] J. Johnson, R. Krishna, M. Stark, L. Li, D.A. Shamma,
M.S. Bernstein, and L. Fei-Fei. Image retrieval using scene
graphs.
In IEEE Conf. on Computer Vision and Pattern
Recognition (CVPR), pages 3668–3678, 2015. 2
[19] J. Kerr, C.M. Kim, K. Goldberg, A. Kanazawa, and M. Tan-
cik.
LERF: Language embedded radiance fields.
In Intl.
Conf. on Computer Vision (ICCV), 2023. 5
[20] Justin Kerr, Chung Min Kim, Ken Goldberg, Angjoo
Kanazawa, and Matthew Tancik. Lerf: Language embedded
radiance fields. In Proceedings of the IEEE/CVF Interna-
tional Conference on Computer Vision, pages 19729–19739,
2023. 2
[21] U. Kim, J. Park, T. Song, and J. Kim. 3-D scene graph: A
sparse and semantic representation of physical environments
for intelligent agents. IEEE Trans. Cybern., PP:1–13, 2019.
2
[22] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao,
Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer White-
head, Alexander C. Berg, Wan-Yen Lo, Piotr Dollar, and
Ross Girshick. Segment anything. In Intl. Conf. on Com-
puter Vision (ICCV), pages 4015–4026, 2023. 2
[23] Harold W. Kuhn. The hungarian method for the assignment
problem. Naval Research Logistics (NRL), 52, 1955. 3
9
