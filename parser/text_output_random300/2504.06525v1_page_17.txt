that it’s orthogonal to the reward 1. c, reward 3 is 180-degree rotated to reward 1 and it’s opposite 
to the reward 1. d, Pareto scatter plot for reward 1 and reward 1 itself. When the two rewards have 
optimal solution overlapping in the parameter space, the Pareto front collapses into a trivial Pareto 
point (the red cross mark) that optimizes both rewards at the same parameter. e, In the case that 
the optimal solution of reward 1 is different from that of reward 2, there will be trade-offs between 
reward 1 and 2 on the Pareto front. f, When the two rewards are opposite to each other, all the 
points in the Pareto scatter plot will be Pareto front points, meaning that at each point, there is no 
another point that can further improve any of the rewards without sacrificing the other reward. The 
green circles in d-f show an example choice of reference in the hyperparameter (rewards) space. 
g, the distribution of Pareto front in the parameter space. Here the reward 1 and reward 2 are plotted 
as solid and dashed contours together, with the red dots representing the same Pareto front in the 
hyperparameter space of panel e. h, the effect of shifting the reference point on the MOBO choice. 
Lowering the reference point for a reward will move the optimal solution away from it along the 
Pareto front. i, the effect of adding weight to the rewards in the acquisition function. Adding extra 
weight (greater than 1) to a reward will also move the optimal solution away from it along the 
Pareto front. 
 
Figures 
Drive Amplitude (nm) Setpoint (%) 
I Gain (a.u.) 
Figure 2-a,b,i 
30.11 
40.32 
66.78 
Figure 2-g 
105.18 
14.18 
30.00 
Figure 2-h 
36.10 
39.58 
73.92 
Figure 4-a,b,e 
29.90 
84.99 
67.56 
Figure 4-f 
30.01 
86.43 
66.64 
Figure 4-g 
30.06 
87.91 
69.43 
Figure 4-h 
30.08 
87.79 
69.70 
Figure 4-i 
29.84 
84.94 
62.73 
Table S1. Detailed controlling parameters for each plot.  
 
