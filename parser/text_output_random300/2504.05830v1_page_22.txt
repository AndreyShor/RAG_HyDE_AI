Springer Nature 2021 LATEX template
22
Human Activity Recognition using RGB-Event based Sensors
Fig. 6 Visualization of confusion matrix on our proposed HARDVS 2.0 dataset.
1.4× (from 88.3GFLOPs to 61.7GFLOPs), and maintains superior perfor-
mance while using only 55% of the parameters (76.1M vs 138.5M). This
significant advantage stems from our novel heat conduction-based multi-modal
model.
Table 7 Comparison of Model Storage Size, Computational Efficiency, and Parameters.
# Models
Storage Size
FLOPs
Params
Multi-modal HCO
309.3MB
61.7G
76.1M
Multi-modal Former
1.04GB
88.3G
138.5M
5.6 Visualization
• Confusion Matrix on HARDVS 2.0.
In this section, we will provide
some visualizations to help readers better understand our dataset and method.
As shown in Fig. 6 (a) and Fig. 6 (b), we present the confusion matrix on the
training and testing subsets of our HARDVS 2.0 dataset. It can be seen that
our model performs much better on the training set than on the testing set,
which indicates that our dataset is highly challenging and there is room for
further optimization of our method on the test set.
• Top-5 Predictions on HARDVS 2.0 and PokerEvent.
As shown
in Fig. 7, we also present the top-5 prediction results on the HARDVS 2.0
and PokerEvent datasets. For visualization, three categories are selected from
each dataset, including set of broadcast gymnastics organizing exercises, Step
in Place, Pull the curtains, Panda, Tiger, and Dolphin. The prediction results
demonstrate that our method can accurately identify categories that match
the ground truth, highlighting its effectiveness in multi-modal human activity
recognition.
• Feature Distribution of ESTF and Ours.
As depicted in Fig. 8 (a)
and (b), we illustrate the feature distribution of multi-modal ESTF and our
