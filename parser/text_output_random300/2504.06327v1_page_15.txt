Physics-informed KAN PointNet
of 2ğ›¼= ğ›½= 2 and ğ›¼= 2ğ›½= 2 results in an average relative error of approximately 13% for the ğ‘¢-component of the
velocity vector, making these two members of the Jacobi polynomial family less suitable for engineering applications.
According to Table 3, from a training perspective, the lowest minimum loss is achieved when ğ›¼= ğ›½= âˆ’0.5.
However, this configuration requires more epochs to converge compared to ğ›¼= ğ›½= 0.5 and 2ğ›¼= ğ›½= 2. The right
panel of Fig. 8 illustrates the evolution of the loss function for different values of ğ›¼and ğ›½. As shown in Fig. 8, all
polynomial types exhibit oscillatory behavior, characterized by sharp jumps at certain epochs during training. Notably,
the Chebyshev polynomials of the first and second kinds (i.e., ğ›¼= ğ›½= âˆ’0.5 and ğ›¼= ğ›½= 0.5) demonstrate smoother
convergence, with smaller and less frequent oscillations, which may indicate greater training stability. In contrast, the
Jacobi polynomials with settings ğ›¼= 2ğ›½= 2 and ğ›¼= ğ›½= 0 exhibit the most pronounced oscillations, with large
abrupt jumps in the loss function. Our conclusion is that, overall, the Chebyshev polynomial demonstrates superior
performance, particularly its first kind, compared to other types of Jacobi polynomials. Considering our discussion in
Sect. 6.1.2, we conclude that the effect of the polynomial degree is more pronounced than the effect of the polynomial
type.
Table 4
Performance comparison of physics-informed PointNet with MLP and physics-informed PointNet with KAN for predicting
the velocity, pressure, and temperature fields across 135 geometries. In physics-informed PointNet with KAN, the Jacobi
polynomial degree is set to 2, with ğ›¼= ğ›½= âˆ’0.5 and ğ‘›ğ‘ = 0.5. In physics-informed PointNet with MLP, ğ‘›ğ‘ = 0.85. || â‹…||ğ‘‰
denotes the ğ¿2 norm over the entire domain ğ‘‰and || â‹…||Î“ represents the ğ¿2 norm over the inner cylinder surface.
Physics-informed PointNet with MLP
Physics-informed PointNet with KAN
Average ||Ìƒğ‘¢âˆ’ğ‘¢||ğ‘‰âˆ•||ğ‘¢||ğ‘‰
1.18367Eâˆ’1
1.08973Eâˆ’1
Maximum ||Ìƒğ‘¢âˆ’ğ‘¢||ğ‘‰âˆ•||ğ‘¢||ğ‘‰
1.37381Eâˆ’1
1.31928Eâˆ’1
Minimum ||Ìƒğ‘¢âˆ’ğ‘¢||ğ‘‰âˆ•||ğ‘¢||ğ‘‰
1.02223Eâˆ’1
8.78500Eâˆ’2
Average || Ìƒğ‘£âˆ’ğ‘£||ğ‘‰âˆ•||ğ‘£||ğ‘‰
8.39424Eâˆ’2
8.84278Eâˆ’2
Maximum || Ìƒğ‘£âˆ’ğ‘£||ğ‘‰âˆ•||ğ‘£||ğ‘‰
1.05331Eâˆ’1
1.11167Eâˆ’1
Minimum || Ìƒğ‘£âˆ’ğ‘£||ğ‘‰âˆ•||ğ‘£||ğ‘‰
6.86013Eâˆ’2
7.06122Eâˆ’2
Average || Ìƒğ‘âˆ’ğ‘||ğ‘‰âˆ•||ğ‘||ğ‘‰
2.61402Eâˆ’2
2.97057Eâˆ’2
Maximum || Ìƒğ‘âˆ’ğ‘||ğ‘‰âˆ•||ğ‘||ğ‘‰
2.91599Eâˆ’2
3.41539Eâˆ’2
Minimum || Ìƒğ‘âˆ’ğ‘||ğ‘‰âˆ•||ğ‘||ğ‘‰
2.04838Eâˆ’2
2.63087Eâˆ’2
Average || Ìƒğ‘‡âˆ’ğ‘‡||ğ‘‰âˆ•||ğ‘‡||ğ‘‰
2.58254Eâˆ’2
2.84486Eâˆ’2
Maximum || Ìƒğ‘‡âˆ’ğ‘‡||ğ‘‰âˆ•||ğ‘‡||ğ‘‰
3.10124Eâˆ’2
3.66225Eâˆ’2
Minimum || Ìƒğ‘‡âˆ’ğ‘‡||ğ‘‰âˆ•||ğ‘‡||ğ‘‰
2.00219Eâˆ’2
2.28196Eâˆ’2
Average || Ìƒğ‘‡âˆ’ğ‘‡||Î“âˆ•||ğ‘‡||Î“
1.45697Eâˆ’2
5.03499Eâˆ’3
Maximum || Ìƒğ‘‡âˆ’ğ‘‡||Î“âˆ•||ğ‘‡||Î“
1.86680Eâˆ’2
9.08389Eâˆ’3
Minimum || Ìƒğ‘‡âˆ’ğ‘‡||Î“âˆ•||ğ‘‡||Î“
9.04055Eâˆ’3
2.59714Eâˆ’3
Minimum loss achieved
3.72039Eâˆ’4
3.03649Eâˆ’4
Training time
15.6
15.4
per epoch (s)
Number of epochs to
2324
2238
reach the minimum loss
Number of trainable
639611
666880
parameters
6.2. Comparison with physics-informed PointNet with MLP
6.2.1. A brief overview of physics-informed PointNet with MLPs
The details of the technical implementation and formulation of physics-informed PointNet with MLPs (commonly
referred to as PIPN) are presented in Refs. [20, 40]. Here, we provide a brief overview and highlight the key differences
between PIPN and PI-KAN-PointNet. The architecture of physics-informed PointNet with MLPs is shown in Fig. 2
of Ref. [20] and Fig. 2 of Ref. [40]. At a high level, its structure is similar to what we present in Fig. 1 of the current
article, with the primary difference being that instead of using shared KANs, we implement shared MLPs. An MLP
A. Kashefi & T. Mukerji: Preprint submitted to Elsevier
Page 15 of 25
