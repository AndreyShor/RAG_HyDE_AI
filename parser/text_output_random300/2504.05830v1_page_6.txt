Springer Nature 2021 LATEX template
6
Human Activity Recognition using RGB-Event based Sensors
under unfavorable lighting conditions or when the movement is too fast. Many
researchers have focused on using event cameras to improve the effectiveness
of human activity recognition tasks. Arnon et al. [20] propose for the first
time a low-power fully event-driven gesture recognition system based on event
hardware, which uses a TrueNorth neural morphology processor to achieve
end-to-end processing and real-time recognition of gestures in events streamed
by dynamic visual sensors (DVS). Xavier et al. [35] propose an event-driven
neuromorphic retina output without brightness features, which maps the opti-
cal flow distribution of moving objects in the field of view to a matrix for
event-based pattern recognition. Chen et al. [36] propose a robust gesture
recognition system based on event-driven neural morphological vision sensors
and active LED-labeled gloves, which can maintain high recognition accuracy
under different lighting and background conditions. Chen et al. [37] propose
an event-driven fast retinal morphology representation method (EDR) that
achieves real-time inference and learning in video games and activity recog-
nition. Xavier et al. [38] represent the recent temporal activity within a local
spatial neighborhood, and utilize the rich temporal information provided by
events to create contexts in the form of time surfaces, termed HOTS, for the
recognition task. Wu et al. [39] first transform the event streams into images,
then predict and combine the human pose with event images for HAR. Graph
neural networks (GNN) and SNNs are also exploited for event-based recogni-
tion. Specifically, Chen et al. [40] treat the event streams as a 3D point cloud
and use dynamic GNNs to learn the spatial-temporal features for gesture recog-
nition. Wang et al. [41] investigate the event streams representation method
for recognizing human gait using deep neural networks. Two different event
streams representations were proposed: image-based representation and graph
based representation, and gait recognition was performed using graph con-
volutional networks and convolutional neural networks, respectively. Xing et
al. [42] propose a novel event based spiking convolutional recurrent neural net-
work (SCRNN) that utilizes convolution operations and recurrent connectivity
to process asynchronous and sparse event sequence data, effectively improving
the accuracy of event-based gesture recognition. Different from these methods,
we are considering combining event streams with RGB modality to achieve
more accurate activity recognition using bimodal RGB-E data and model.
2.2 RGB-Event based HAR
To address the limited performance of traditional RGB cameras in extreme
environments and enhance the representation capability of event data, the
RGB-E based multi-modal human activity recognition task has been exten-
sively explored by researchers. Huang et al. [43] propose VEFNet, a cross-
modal fusion network that combines event streams and RGB images for visual
position recognition, effectively addressing the challenges posed by lighting
and seasonal changes, and achieving long-term localization. Wang et al. [44]
integrate RGB frames and event streams by using a memory supported trans-
former network and a pulse neural network, a multi-modal bottleneck fusion
