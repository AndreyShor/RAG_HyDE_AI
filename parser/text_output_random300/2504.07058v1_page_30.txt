5
Conclusion
This paper presents Physics-Informed Neural Networks (PINNs) for approximating solutions to partial differential
equations in the modeling of low-grade brain tumors.
The approach involves training a neural network to
approximate classical solutions by minimizing the residuals of the governing PDE. Both well-posed problems
(with initial and boundary conditions) and ill-posed problems (without complete initial or boundary data) are
considered, using a gradient-based optimization method. Theoretical error bounds for the PINN approximation
are derived, and both forward and inverse numerical experiments are conducted to demonstrate the effectiveness
of PINNs in solving linear and nonlinear PDEs efficiently. Glioblastoma is a frequently occurring malignant brain
tumor in adults, characterized by rapid progression and an unfavorable prognosis. Standard treatment typically
involves a combination of surgery, radiation therapy, and chemotherapy. In recent years, mathematical modeling
has played a crucial role in studying brain tumors under both treated and untreated conditions. This study
presents a mathematical model for glioblastoma, integrating key factors of tumor growth: cancer cell diffusion and
proliferation rates. The PINN method was applied to obtain numerical solutions for the nonlinear biharmonic
EFK equation, which arises in brain tumor dynamics, as well as the Burgesss equation. A comparison with
other mesh-less local weak-form methods demonstrated that the PINN Algorithm effectively solves forward and
inverse nonlinear fourth-order PDEs, particularly the EFK equation and the first-order Burgesss equation relevant
to brain tumor modeling. The results strongly correlate with established exact solutions, while graphical and
tabular analyses indicate that the advanced PINNs method achieves superior accuracy in brain tumor modeling,
exceeding traditional computational techniques. We derive rigorous error bounds for PINNs and perform numerical
experiments to assess their accuracy in solving both linear and nonlinear equations. Additionally, we establish the
convergence and reliability of the neural network.
Declaration of competing interest
The authors declare that they have no competing interests.
Acknowledgment
The first author acknowledges the Ministry of Human Resource Development (MHRD), Government of India, for
providing institutional funding and support at IIT Madras.
Appendix
An estimate for the generalization error of the given equation is derived for forward problems.
Appendix E.1. Let ğ‘¢âˆˆğ¶2(D Ã— [0,ğ‘‡]) be the unique classical solution of the Burgess equation (2.7), where the
source term ğ‘…satisfies Lipchitz condition (Appendix E.6). Consider ğ‘¢âˆ—= ğ‘¢ğœƒâˆ—, a PINN approximation obtained
through Algorithm 2.1, corresponding to the loss functions (2.31) and (2.32). Then, the generalization error (2.34)
satisfies the following bound:
Eğºâ©½ğ¶1

Eğ‘¡ğ‘
ğ‘‡+ Eğ‘–ğ‘›ğ‘¡
ğ‘‡
+ ğ¶2(Eğ‘ ğ‘
ğ‘‡)
1
2 + (ğ¶ğ‘¡ğ‘
ğ‘ğ‘¢ğ‘ğ‘‘)
1
2 ğ‘âˆ’ğ›¼ğ‘¡ğ‘
2
ğ‘¡ğ‘
+ (ğ¶ğ‘–ğ‘›ğ‘¡
ğ‘ğ‘¢ğ‘ğ‘‘)
1
2 ğ‘âˆ’ğ›¼ğ‘–ğ‘›ğ‘¡
2
ğ‘–ğ‘›ğ‘¡
+ ğ¶2(ğ¶ğ‘ ğ‘
ğ‘ğ‘¢ğ‘ğ‘‘)
1
4 ğ‘âˆ’ğ›¼ğ‘ ğ‘
4
ğ‘ ğ‘

,
(5.1)
where the constants are given by:
ğ¶1 =
âˆšï¸ƒ
ğ‘‡+ (1 + 2ğ¶ğ‘…)ğ‘‡2ğ‘’(1+2ğ¶ğ‘…)ğ‘‡,
ğ¶2 =
âˆšï¸ƒ
ğ¶ğœ•D(ğ‘¢, ğ‘¢âˆ—)ğ‘‡
1
2 ,
ğ¶ğœ•D = 0.5|ğœ•D|
1
2

âˆ¥ğ‘¢âˆ¥ğ¶1([0,ğ‘‡]Ã—ğœ•D)+âˆ¥ğ‘¢âˆ—âˆ¥ğ¶1([0,ğ‘‡]Ã—ğœ•D)

.
(5.2)
The constants ğ¶ğ‘¡ğ‘
ğ‘ğ‘¢ğ‘ğ‘‘= ğ¶ğ‘¡ğ‘
ğ‘ğ‘¢ğ‘ğ‘‘(âˆ¥â„œ2
ğ‘¡ğ‘,ğœƒâˆ—âˆ¥ğ¶2), ğ¶ğ‘ ğ‘
ğ‘ğ‘¢ğ‘ğ‘‘= ğ¶ğ‘¡ğ‘
ğ‘ğ‘¢ğ‘ğ‘‘(âˆ¥â„œ2
ğ‘ ğ‘,ğœƒâˆ—âˆ¥ğ¶2), and ğ¶ğ‘–ğ‘›ğ‘¡
ğ‘ğ‘¢ğ‘ğ‘‘= ğ¶ğ‘–ğ‘›ğ‘¡
ğ‘ğ‘¢ğ‘ğ‘‘(âˆ¥â„œ2
ğ‘–ğ‘›ğ‘¡,ğœƒâˆ—âˆ¥ğ¶0) arise
from the quadrature error.
Proof. The proof follows the approach of [35] (see Theorem 3.1). The authors briefly discuss a related argument
in [46].
â–¡
30
