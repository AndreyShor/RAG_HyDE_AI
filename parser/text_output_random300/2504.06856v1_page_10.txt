of 3d shapes and textures. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition,
pages 12663–12673, 2023. 1, 2
[24] Oscar Michel, Roi Bar-On, Richard Liu, Sagie Benaim, and
Rana Hanocka. Text2mesh: Text-driven neural stylization
for meshes. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pages 13492–
13502, 2022. 2
[25] Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik,
Jonathan T Barron, Ravi Ramamoorthi, and Ren Ng. Nerf:
Representing scenes as neural radiance fields for view syn-
thesis. Communications of the ACM, 65(1):99–106, 2021.
1
[26] Nasir Mohammad Khalid, Tianhao Xie, Eugene Belilovsky,
and Tiberiu Popa. Clip-mesh: Generating textured meshes
from text using pretrained image-text models. In SIGGRAPH
Asia 2022 conference papers, pages 1–8, 2022. 2
[27] Jacob Munkberg, Jon Hasselgren, Tianchang Shen, Jun Gao,
Wenzheng Chen, Alex Evans, Thomas M¨uller, and Sanja
Fidler.
Extracting Triangular 3D Models, Materials, and
Lighting From Images. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition (CVPR),
pages 8280–8290, 2022. 3
[28] Michael Oechsle, Lars Mescheder, Michael Niemeyer, Thilo
Strauss, and Andreas Geiger. Texture fields: Learning tex-
ture representations in function space. In Proceedings of
the IEEE/CVF International Conference on Computer Vision,
pages 4531–4540, 2019. 2
[29] Ben Poole, Ajay Jain, Jonathan T Barron, and Ben Mildenhall.
Dreamfusion: Text-to-3d using 2d diffusion. arXiv preprint
arXiv:2209.14988, 2022. 1, 2, 3, 5
[30] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya
Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,
Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning
transferable visual models from natural language supervi-
sion. In International conference on machine learning, pages
8748–8763. PMLR, 2021. 2
[31] Elad Richardson, Gal Metzer, Yuval Alaluf, Raja Giryes,
and Daniel Cohen-Or. Texture: Text-guided texturing of 3d
shapes. In ACM SIGGRAPH 2023 conference proceedings,
pages 1–11, 2023. 2
[32] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Patrick Esser, and Bj¨orn Ommer. High-resolution image
synthesis with latent diffusion models. In Proceedings of
the IEEE/CVF conference on computer vision and pattern
recognition, pages 10684–10695, 2022. 1, 2
[33] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li,
Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael
Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Pho-
torealistic text-to-image diffusion models with deep language
understanding. Advances in neural information processing
systems, 35:36479–36494, 2022. 1, 2
[34] Yichun Shi, Peng Wang, Jianglong Ye, Mai Long, Kejie Li,
and Xiao Yang. Mvdream: Multi-view diffusion for 3d gener-
ation. arXiv preprint arXiv:2308.16512, 2023. 2
[35] Alex Shonenkov, Misha Konstantinov, Daria Bakshandaeva,
Christoph Schuhmann, Ksenia Ivanova, and Nadiia Klokova.
Deepfloyd-if. Hugging Face, 2023. 5
[36] Yawar Siddiqui, Justus Thies, Fangchang Ma, Qi Shan,
Matthias Nießner, and Angela Dai. Texturify: Generating
textures on 3d shape surfaces. In European Conference on
Computer Vision, pages 72–88. Springer, 2022. 2
[37] Jiaxiang Tang, Jiawei Ren, Hang Zhou, Ziwei Liu, and Gang
Zeng. Dreamgaussian: Generative gaussian splatting for effi-
cient 3d content creation. arXiv preprint arXiv:2309.16653,
2023. 3
[38] Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky.
Deep image prior. In Proceedings of the IEEE conference on
computer vision and pattern recognition, pages 9446–9454,
2018. 4, 5, 8
[39] Ximing Xing, Haitao Zhou, Chuang Wang, Jing Zhang, Dong
Xu, and Qian Yu. Svgdreamer: Text guided svg generation
with diffusion model. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition, pages
4546–4555, 2024. 3
[40] Taoran Yi, Jiemin Fang, Guanjun Wu, Lingxi Xie, Xiaopeng
Zhang, Wenyu Liu, Qi Tian, and Xinggang Wang. Gaussian-
dreamer: Fast generation from text to 3d gaussian splatting
with point cloud priors. arXiv preprint arXiv:2310.08529,
2023. 3
[41] Kim Youwang, Tae-Hyun Oh, and Gerard Pons-Moll. Paint-it:
Text-to-texture synthesis via deep convolutional texture map
optimization and physically-based rendering. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, pages 4347–4356, 2024. 1, 2, 3, 4, 5
[42] Rui Yu, Yue Dong, Pieter Peers, and Xin Tong. Learning
texture generators for 3d shape collections from internet photo
sets. In British Machine Vision Conference, 2021. 2
[43] Xianfang Zeng, Xin Chen, Zhongqi Qi, Wen Liu, Zibo Zhao,
Zhibin Wang, Bin Fu, Yong Liu, and Gang Yu. Paint3d:
Paint anything 3d with lighting-less texture diffusion models.
In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pages 4252–4262, 2024. 2
