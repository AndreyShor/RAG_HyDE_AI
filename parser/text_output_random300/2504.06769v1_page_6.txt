6
to the PDG. Specifically, under the linear benefit function, co-
operation in PGG emerges when the benefit-to-cost ratio sat-
isfies b/c >
(k+1)2
k+3 , a condition that is less stringent than
that of the PDG, where cooperation emerges at b/c > k. For
the saturating benefit function, the condition for cooperation
to emerge is b/c >
(k+1)
βsat(k+3), which is also weaker than the
cooperation condition in the PDG, where b/c > k/βsat.
In comparison to Ref. [40], which examined the evolution
of cooperation in the spatial public goods game with two dis-
crete strategies, we investigate the evolution of continuous in-
vestments. For linear benefit functions, we find that strate-
gies eventually evolve toward either full cooperation or full
defection in both the discrete and continuous scenarios. No-
tably, the range of benefit-to-cost ratios corresponding to these
two evolutionary outcomes coincides exactly in both scenar-
ios. Indeed, Ref. [40] considered the evolution of coopera-
tion when the benefit function is a step-like function. For the
convenience of theoretical analysis, the authors analyzed the
evolutionary dynamics when the parameter threshold is set to
the maximum T = n and identified the potential existence of
a repellor. This evolutionary outcome aligns with our find-
ings in PGG with sigmoid benefit functions. The discrepancy
in benefit-to-cost ratios associated with the repellor in contin-
uous and discrete scenarios may be attributed to the use of
distinct benefit functions. Remarkably, we consider a gener-
alized sigmoid benefit function in our study. In addition, we
explore how the varying threshold T can impact evolutionary
outcomes. Our work thus further enriches the knowledge of
the evolutionary dynamics of PGG with different benefit func-
tions.
In this work, we have focused on the evolutionary dynam-
ics of continuous public goods games in regular networks. In
future work, it would be interesting to study the evolutionary
dynamics in heterogeneous networks [63, 64]. Furthermore, it
is also worthwhile to study the evolutionary dynamics of co-
operation when incentives are integrated into the continuous
PGG we considered [65, 66].
Appendix A: Calculation details under the pair approximation
approach
For continuous games in spatially structured populations,
the frequency dynamics of two types, the resident and the mu-
tant, can be modeled using the pair approximation approach
[55–59]. Correspondingly, we use the notations PX and PXY
to respectively represent the frequencies of X resident and XY
pairs in the population. Let qX|Y denote the conditional prob-
ability to find an individual with strategy X given that the adja-
cent node is occupied by a neighbor with strategy Y. Let both
X and Y stand for m and r, and based on the above-mentioned
descriptions we have
Pm + Pr = 1,
(A1)
Pmr = Prm,
(A2)
Pmr = Prqm|r,
(A3)
and
qm|m + qr|m = 1.
(A4)
Note that the whole system can be fully described by using
only two variables pm and qm|m. Moreover, the respective
rates of change depend on the microscopic updating proce-
dure. In the following, we calculate the dynamical changes of
the frequency of mutant pm for death-birth updating.
1.
Updating a resident
For the two types: a mutant type with trait value y and a
resident type with trait value x, the collected contribution in
the public pool organized by individual i equals τi(j) = jy +
(n−j)x, where j represents the number of y-strategists in the
group. Correspondingly, the payoff of the mutant and resident
in one interaction group can be respectively given by
πm(j) = B(jy + (n −j)x) −C(y),
(A5)
and
πr(j) = B(jy + (n −j)x) −C(x),
(A6)
where n = k + 1 represents the group size.
We further consider that a resident is replaced by a neigh-
boring mutant in the regular network. We assume that there
are j mutants among the k nearest neighbors. By considering
the possible configurations around the resident, we can esti-
mate its mutant and resident neighbors’ payoff values. Ac-
cordingly, the total payoff of the mutant player, who is the
neighbor of the selected resident individual, can be given as
Πr
m(j) = πm(j)
+
k−1
X
i=0
k −1
i

qi
m|m(1 −qm|m)k−1−i(πm(i + 1)
+ i
k−1
X
t=0
k −1
t

qt
m|m(1 −qm|m)k−1−tπm(t + 2)
+ (k −1 −i)
k−1
X
t=0
k −1
t

qt
m|r(1 −qm|r)k−1−tπm(t + 1)).
(A7)
The payoff of his/her resident neighbor can be given as
Πr
r(j) = πr(j)
+
k−1
X
i=0
k −1
i

qi
m|r(1 −qm|r)k−1−i(πr(i)
+ i
k−1
X
t=0
k −1
t

qt
m|m(1 −qm|m)k−1−tπr(t + 1)
+ (k −1 −i)
k−1
X
t=0
k −1
t

qt
m|r(1 −qm|r)k−1−tπr(t)).
(A8)
