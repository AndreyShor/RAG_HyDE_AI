[16] S. Jan, G. Santin, D. Strul, S. Staelens, K. Assi´e, D. Autret, S. Avner,
R. Barbier, M. Bardies, P. Bloomﬁeld et al., “Gate: a simulation toolkit
for pet and spect,” Physics in Medicine & Biology, vol. 49, no. 19, p.
4543, 2004.
[17] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf,
E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner,
L. Fang, J. Bai, and S. Chintala, “Pytorch: An imperative style, high-
performance deep learning library,” in Advances in Neural Information
Processing Systems, vol. 32.
Curran Associates, Inc., 2019.
[18] J. K. Eshraghian, M. Ward, E. Neftci, X. Wang, G. Lenz, G. Dwivedi,
M. Bennamoun, D. S. Jeong, and W. D. Lu, “Training spiking
neural networks using lessons from deep learning,” arXiv preprint
arXiv:2109.12894, 2021.
[19] O. Taubert, M. Weiel, D. Coquelin, A. Farshian, C. Debus, A. Schug,
A. Streit, and M. G¨otz, “Massively parallel genetic optimization through
asynchronous propagation of populations,” in International Conference
on High Performance Computing.
Springer, 2023, pp. 106–124.
[20] C. Debus, M. Piraud, A. Streit, F. Theis, and M. G¨otz, “Reporting
electricity consumption is essential for sustainable ai,” Nature Machine
Intelligence, pp. 1–3, 2023.
[21] J. P. Guti´errez Hermosillo Muriedas, K. Fl¨ugel, C. Debus, H. Obermaier,
A. Streit, and M. G¨otz, “perun: Benchmarking energy consumption of
high-performance computing applications,” in Euro-Par 2023: Parallel
Processing.
Springer International Publishing, 2023, pp. 1–15.
[22] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
in 3rd International Conference on Learning Representations, Y. Bengio
and Y. LeCun, Eds.
ICLR, 2015.
[23] D. Coquelin, C. Debus, M. G¨otz, F. von der Lehr, J. Kahn, M. Siggel,
and A. Streit, “Accelerating neural network training with distributed
asynchronous and selective optimization (daso),” Journal of Big Data,
vol. 9, no. 1, p. 14, 2022.
[24] P. Nakkiran, G. Kaplun, Y. Bansal, T. Yang, B. Barak, and I. Sutskever,
“Deep double descent: Where bigger models and more data hurt,”
Journal of Statistical Mechanics: Theory and Experiment, vol. 2021,
no. 12, p. 124003, 2021.
[25] C. D. Pain, G. F. Egan, and Z. Chen, “Deep learning-based image recon-
struction and post-processing methods in positron emission tomography
for low-dose imaging and resolution enhancement,” European Journal
of Nuclear Medicine and Molecular Imaging, vol. 49, no. 9, pp. 3098–
3118, 2022.
[26] X. Dong, Y. Lei, T. Wang, K. Higgins, T. Liu, W. J. Curran, H. Mao,
J. A. Nye, and X. Yang, “Deep learning-based attenuation correction in
the absence of structural information for whole-body positron emission
tomography imaging,” Physics in Medicine & Biology, vol. 65, no. 5,
p. 055011, 2020.
[27] A. U. Rahman, M. V. Nemallapudi, C.-Y. Chou, C.-H. Lin, and S.-C.
Lee, “Direct mapping from pet coincidence data to proton-dose and
positron activity using a deep learning approach,” Physics in Medicine
& Biology, vol. 67, no. 18, p. 185010, 2022.
[28] M. Hamdi, S. Bourouis, K. Rastislav, F. Mohmed et al., “Evaluation
of neuro images for the diagnosis of alzheimer’s disease using deep
learning neural network,” Frontiers in Public Health, vol. 10, p. 834032,
2022.
[29] J.-D. Leroux, M.-A. Tetrault, D. Rouleau, C. M. Pepin, J.-B. Michaud,
J. Cadorette, R. Fontaine, and R. Lecomte, “Time discrimination tech-
niques using artiﬁcial neural networks for positron emission tomogra-
phy,” IEEE Transactions on Nuclear Science, vol. 56, no. 3, pp. 588–595,
2009.
[30] H. Arabi, A. AkhavanAllaf, A. Sanaat, I. Shiri, and H. Zaidi, “The
promise of artiﬁcial intelligence and deep learning in pet and spect
imaging,” Physica Medica, vol. 83, pp. 122–137, 2021.
[31] E. Fuster-Garcia, J. Oliver, J. Cabello, S. Tortajada, and M. Rafecas,
“Reduction of random coincidences in small animal pet using artiﬁcial
neural networks,” in IEEE Nuclear Science Symposuim & Medical
Imaging Conference.
IEEE, 2010, pp. 2308–2313.
[32] F. Kamaruzaman, A. A. Shaﬁe, Y. M. Mustafah et al., “Coincidence
detection using spiking neurons with application to face recognition,”
Journal of Applied Mathematics, vol. 2015, 2015.
[33] S. R. Kulkarni, A. Young, P. Date, N. Rao Miniskar, J. Vetter, F. Fahim,
B. Parpillon, J. Dickinson, N. Tran, J. Yoo et al., “On-sensor data
ﬁltering using neuromorphic computing for high energy physics ex-
periments,” in Proceedings of the 2023 International Conference on
Neuromorphic Systems, 2023, pp. 1–8.
[34] Y. Guo, Y. Chen, L. Zhang, X. Liu, Y. Wang, X. Huang, and Z. Ma,
“Im-loss: information maximization loss for spiking neural networks,”
Advances in Neural Information Processing Systems, vol. 35, pp. 156–
166, 2022.
[35] D. J. K¨osters, B. A. Kortman, I. Boybat, E. Ferro, S. Dolas, R. Ruiz de
Austri, J. Kwisthout, H. Hilgenkamp, T. Rasing, H. Riel et al., “Bench-
marking energy consumption and latency for neuromorphic computing in
condensed matter and particle physics,” APL Machine Learning, vol. 1,
no. 1, 2023.
