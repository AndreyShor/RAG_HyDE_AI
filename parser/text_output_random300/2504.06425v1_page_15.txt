NEURAL NETWORK POLYCONVEXIFICATION
15
−1
−0.5
0
0.5
1
0
1
2
3
ν1
Φ((ν1, 0); λ, α)
Φpc((ν1, 0); λ, α)
Φpc
pred((ν1, 0); λ, α)
±σ
(a) cross-section along the (ν1,0)-axis.
−1
−0.5
0
0.5
1
0
2
4
ν1
Φ((ν1, ν1); λ, α)
Φpc(ν1, ν1)
Φpc
pred((ν1, ν1); λ, α)
±σ
(b) cross-section along the (ν1,ν1)-axis.
Figure 7. Comparison along two axes of the predicted polyconvex envelope Φpc
pred
(averaged over ten network realisations) and the analytical polyconvex envelope
Φpc for the Generalised Kohn–Strang–Dolzmann function with λ = 1.7 and
α = 1.3. The standard deviation of the ten predictions is marked by σ.
−1
−0.5
0
0.5
1
0
1
2
3
ν1
Φ((ν1, 0); λ, α)
Φpc((ν1, 0), λ, α)
Φpc
pred((ν1, 0); λ, α)
±σ
(a) cross-section along the (ν1, 0)-axis.
−1
−0.5
0
0.5
1
0
2
4
6
ν1
Φ((ν1, ν1); λ, α)
Φpc((ν1, ν1); λ, α)
Φpc
pred((ν1, ν1); λ, α)
±σ
(b) cross-section along the (ν1,ν1)-axis.
Figure 8. Comparison along two axes of the predicted polyconvex envelope
Φpc
pred (averaged over ten network realisations) and the analytical polyconvex
envelope Φpc for the Generalised Kohn–Strang–Dolzmann function with λ = 1
and α = 2.1, these parameters are located outside the parameter learning
domain. The standard deviation of the ten predictions is marked by σ.
particular, the neural network implemented in this example contains 3344 parameters, comprising
both weights and biases. With the same number of parameters using the conventional approach,
it would only be possible to store a 19 × 19 grid, with 3 values for each λ and α. With this
limited grid size, it is evident that the full range of data cannot be recovered with the same
precision as is achievable with neural networks presented here.
