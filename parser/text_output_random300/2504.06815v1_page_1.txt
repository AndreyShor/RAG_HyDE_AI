SVG-IR: Spatially-Varying Gaussian Splatting for Inverse Rendering
Hanxiao Sun1
Yupeng Gao2
Jin Xie2
Jian Yang1
Beibei Wang2∗
1Nankai University
2Nanjing University
Novel View Synthesis
Relighting
Visibility & Indirect Shading
Albedo & Normal
Spatially-varying Gaussian
Gaussian Vertex Normal
Shading Normal
Gaussian Normal
Material Attribute
Gaussian Vertex
Shading Point
Constant Gaussian
(Original)
(Ours)
Flat Shading
Interpolated Shading
Interpolate
Copy
Figure 1. SVG-IR introduces a new spatially-varying Gaussian representation inspired by replacing flat shading for interpolated shading
in triangle rendering. Each spatially-varying Gaussian allows spatially-varying material and normal attributes by interpolating among
Gaussian vertices defined in the tangent space of a Gaussian. Compared to the original Gaussian (i.e., Constant Gaussian) with constant
attributes, SVG has a more powerful representation ability to produce high-quality NVS and relighting results.
Abstract
Reconstructing 3D assets from images, known as inverse
rendering (IR), remains a challenging task due to its ill-
posed nature. 3D Gaussian Splatting (3DGS) has demon-
strated impressive capabilities for novel view synthesis
(NVS) tasks.
Methods apply it to relighting by separat-
ing radiance into BRDF parameters and lighting, yet pro-
duce inferior relighting quality with artifacts and unnatural
indirect illumination due to the limited capability of each
Gaussian, which has constant material parameters and nor-
mal, alongside the absence of physical constraints for indi-
rect lighting. In this paper, we present a novel framework
called Spatially-vayring Gaussian Inverse Rendering (SVG-
IR), aimed at enhancing both NVS and relighting quality.
To this end, we propose a new representation—Spatially-
varying Gaussian (SVG)—that allows per-Gaussian spa-
tially varying parameters.
This enhanced representation
is complemented by a SVG splatting scheme akin to ver-
tex/fragment shading in traditional graphics pipelines. Fur-
thermore, we integrate a physically-based indirect lighting
model, enabling more realistic relighting.
The proposed
* Corresponding author.
1 College of Computer Science, Nankai University, Tianjin, China
2 School of Intelligence Science and Technology, Nanjing University,
Suzhou, China
SVG-IR framework significantly improves rendering qual-
ity, outperforming state-of-the-art NeRF-based methods by
2.5 dB in peak signal-to-noise ratio (PSNR) and surpassing
existing Gaussian-based techniques by 3.5 dB in relighting
tasks, all while maintaining a real-time rendering speed.
The source code is available at https://github.com/learner-
shx/SVG-IR.
1. Introduction
Reconstructing 3D assets from images, or so-called in-
verse rendering (IR), is a longstanding task in computer
graphics and vision. While recent techniques (e.g., Neu-
ral Radiance Fields (NeRF) [22] and 3D Gaussian Splatting
(3DGS) [16]) have brought great opportunities to this task,
it is still challenging due to its ill-posed nature and the com-
plexity of both appearance and lighting.
Existing NeRF-based IR methods [2, 3, 8, 25, 27, 33, 35]
have achieved impressive relighting quality, at the cost of
long training and rendering time. Recently, several meth-
ods [6, 11, 19, 24] have incorporated 3DGS into IR by de-
coupling radiance into material parameters for a Bidirec-
tional Reflectance Distribution Function (BRDF) and envi-
ronmental lighting to achieve relightability. Despite their
fast training and rendering speeds, the quality of relighting
often suffers from noticeable artifacts in both training and
arXiv:2504.06815v1  [cs.CV]  9 Apr 2025
