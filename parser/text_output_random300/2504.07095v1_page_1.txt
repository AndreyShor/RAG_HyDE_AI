Neural Motion Simulator
Pushing the Limit of World Models in Reinforcement Learning
Chenjie Hao1∗, Weyl Lu1∗, Yifan Xu2, Yubei Chen1,2†
1UC Davis
2Open Path AI Foundation
{cjhao, adslu, ybchen}@ucdavis.edu, yifan.xu@openpathai.com
Figure 1. This figure demonstrate the long-horizon precise prediction by the Neural Motion Simulators. In each of the three pictures, the
first row shows the ground-truth states and the second row shows the predicted states with the same initial condition and actions sequence.
Humanoid predicts for 30 steps with rendering every 3 steps; Panda predicts for 200 steps with rendering every 20 steps; myohand predicts
for 400 steps with rendering every 40 steps.
Abstract
An embodied system must not only model the patterns of
the external world but also understand its own motion dy-
namics. A motion dynamic model is essential for efficient
skill acquisition and effective planning. In this work, we
introduce the neural motion simulator (MoSim), a world
model that predicts the future physical state of an embodied
system based on current observations and actions. MoSim
achieves state-of-the-art performance in physical state pre-
diction and provides competitive performance across a
range of downstream tasks. This works shows that when
a world model is accurate enough and performs precise
long-horizon predictions, it can facilitate efficient skill ac-
quisition in imagined worlds and even enable zero-shot
∗Equal Contribution. †Corresponding Author
reinforcement learning.
Furthermore, MoSim can trans-
form any model-free reinforcement learning (RL) algorithm
into a model-based approach, effectively decoupling physi-
cal environment modeling from RL algorithm development.
This separation allows for independent advancements in
RL algorithms and world modeling, significantly improv-
ing sample efficiency and enhancing generalization capa-
bilities. Our findings highlight that world models for mo-
tion dynamics is a promising direction for developing more
versatile and capable embodied systems.
1. Introduction
Human and other animals build world models of the ex-
ternal world and themselves to efficiently learn skills, rea-
son, and plan [1]. By using such a world model, natural
intelligence can learn tasks with a small exposure or gen-
1
arXiv:2504.07095v1  [cs.LG]  9 Apr 2025
