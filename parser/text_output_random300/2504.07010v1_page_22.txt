IBM fake backends, fake cusco, fake kawasaki, fake kyiv’, fake kyoto,
and fake osaka, and using Qiskit Aer simulator. All simulations produced
Mshots = 1000 quantum shots per run. We designed four different setups
to test the mitigation strategies of Section 2.5, all, mondrian, shift, and
shift+mondrian. In shift+mondrian, we followed the procedure described
in Appendix 3.1, where the shift model, g, was a Scikit-Learn Random Forest
regressor with default parameters, ϕ(ˆY ) = [EˆY , vec(E(ˆY −EˆY )⊗(ˆY −EˆY ))],
and A ∈{dBC, dKL, dTV}. In all and mondrian, we did not train any shift
model and used data from circuits with sizes s < smax = 15 (all) and s =
s2nd max = 13 (mondrian) for calibration. In shift and shift+mondrian,
we trained the shift model on a randomly selected half of all s < smax data
(shift) and only on s < s2nd max data (shift+mondrian). In both cases, we
let the calibration set contain all the remaining s < smax data. The test set
always consisted of all s = smax = 15 data. Table 1 shows the average size
and coverage of the CP prediction intervals for all setups.
3.5
Real data
Finally, we tested the algorithms on hardware data from Martina et al.
(2022). We selected data generated by running 9 modular 4-qubit walker
circuits of increasing depth on different quantum machines. Figure 2 shows a
walker circuit of depth 3. The others were obtained by repeating its structure
2 and 3 times (see Martina et al. (2022) for more details). Each circuit ran
on 5 different quantum machines, ibm athens, ibm casablanca, ibm lima,
ibm quito, and santiago, with Mshots = 1000 quantum shots per execu-
tion. The corresponding noise-free data were generated using Qiskit’s Aer
simulator (Qiskit, 2025). We followed the procedure described in Appendix
3.1 and considered the same distribution distances and setups of Section 3.4
with s replaced by the circuit depths. The algorithms were all tested on data
generated by the deepest circuit (depth = 9). Table 2 shows the average size
and coverage of the CP prediction intervals for all setups.
3.6
Discussion
Synthetic data
The proposed density-ratio estimation seems to be a good
proxy for the theoretical Bhattacharyya distance. The differences between
dKL and dBC and dTV for higher levels of noise show that dTV ignores fea-
tures accounted by the other distances. The strong similarity between dKL
