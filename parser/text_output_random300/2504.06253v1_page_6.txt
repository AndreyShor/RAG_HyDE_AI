6
â€¢
Bhattacharyya et al.
We can also define Hamiltonians3 ğ»QUBO
ğ‘„
and ğ»Max-Cut
ğ½
as (where ğ‘ğ‘–is the Pauli ğ‘applied to qubit ğ¼)
ğ»Q
ğ‘„=
âˆ‘ï¸
0â‰¤ğ‘–,ğ‘—<ğ‘›
ğ‘„ğ‘–,ğ‘—
1 âˆ’ğ‘ğ‘–
2
 1 âˆ’ğ‘ğ‘–
2

,
ğ»M
ğ´= âˆ’1
4
âˆ‘ï¸
0â‰¤ğ‘–,ğ‘—<ğ‘›
ğ´ğ‘–,ğ‘—ğ‘ğ‘–ğ‘ğ‘—.
(18)
Which in turn satisfy
âŸ¨ğœ“(ğ‘¥)|ğ»Q
ğ‘„|ğœ“(ğ‘¥)âŸ©= ğ‘¥ğ‘‡ğ‘„ğ‘¥,
âŸ¨ğœ“(ğ‘¦)|ğ»M
ğ´|ğœ“(ğ‘¦)âŸ©= âˆ’1
4ğ‘¦ğ‘‡ğ´ğ‘¦.
(19)
Now, given the QUBO problem associated with ğ‘„, it can be solved by either
â€¢ Running QAOA with ğ»ğ¶= ğ»Q
ğ‘„.
â€¢ Running QAOA with ğ»ğ¶= ğ»M
ğ´where ğ´is the adjacency matrix of the corresponding graph of ğ‘„.
3
Methods
3.1
Warm-start Quantum Optimization
Warm-start QAOA refers to using information about the Hamiltonian ğ»ğ¶to determine an appropriate initial
state, |ğœ“initâŸ©.
3.1.1
QUBO-Relaxed. The QUBO-Relaxed warmstart (see [5, 8]) is inspired by the following relaxation of a
QUBO. Given a symmetric ğ‘„âˆˆRğ‘›Ã—ğ‘›, let
ğ‘¦ğ‘= arg max
ğ‘¦âˆˆ[0,1]ğ‘›ğ‘¦ğ‘‡ğ‘„ğ‘¦.
(20)
In the event that ğ‘„is negative semidefinite, it is known that the above relaxation is convex4 and thus can be
solved efficiently [20]. However, for arbitrary ğ‘„, solving the relaxation is known to be NP-Hard [9] meaning
that, unless ğ‘ƒ= ğ‘ğ‘ƒ, there is no algorithm that is guaranteed to find the global optimum in polynomial time.
As discussed later in our numerical results, for general ğ‘„, we instead estimate ğ‘¦ğ‘by considering random initial
points in the box [0, 1]ğ‘›and performing a local optimization.
Given a positive real hyperparameter ğœ€> 0, the QUBO-Relaxed initial state for ğ»QUBO
ğ‘„
is given by
|ğœ“ğ‘—âŸ©= ğ‘…ğ‘Œ(ğœƒğ‘—)|0âŸ©
where
ğœƒğ‘—=
ï£±ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£³
2 arcsin(ğœ€)
if
ğ‘¦ğ‘
ğ‘—â‰¤ğœ€
2 arcsin(ğ‘¦ğ‘
ğ‘—)
if
ğœ€â‰¤ğ‘¦ğ‘
ğ‘—â‰¤1 âˆ’ğœ€
2 arcsin(1 âˆ’ğœ€)
if
ğ‘¦ğ‘
ğ‘—â‰¥1 âˆ’ğœ€
.
(21)
3Here ğ‘„and ğ‘€refer to QUBO and Max-Cut respectively.
4Technically, the objective is a concave function; however convex optimization is usually considered in the context of minimization problems
and minimization of a convex objective ğ‘“is equivalent to maximization of the concave objective âˆ’ğ‘“. In general, we abuse this language
and say that an optimization problem â€œis convex" whenever a convex objective is being minimized or when a concave objective is being
maximized.
ACM Trans. Quantum Comput., Vol. 1, No. 1, Article . Publication date: April 2025.
