Fig. 13: Human extracting box as the robot provides assistance
Fig. 14: Robot extracting box as the human provides assistance
and planning a safe extraction sequence. In collaborative
shelf clearing, human and robot share the task, resulting in
increased efficiency (up to 2 times faster execution time) and
safety compared to individual efforts. Furthermore, the col-
laborative support assistance demonstrates the framework’s
ability to facilitate in-contact collaboration, where the robot
either stabilizes neighboring boxes or works with the human
to maintain shelf integrity. The framework’s reliance on
visual cues and voice commands establishes clear, real-time
communication, enabling effective decision-making in real-
world settings.
V. CONCLUSIONS
In this paper, we proposed a novel multi-modal interaction
framework, integrating a physics-informed Box Relations
Graph (BRG) and an LLM-driven interface, to facilitate
intuitive and safe shelf-picking operations. Real-world ex-
periments validated the framework’s effectiveness in gesture-
guided extraction, collaborative shelf clearing, and stability
assistance, demonstrating its practical application in human-
centric warehouse environments.
We plan on extending our work in the future by ex-
panding the system’s applicability to generalized robotic
manipulation scenarios, implement it on mobile manipulator
platforms, conduct more extensive experimental analyses, in-
crease inference speed for real-time performance and explore
advanced learning techniques to further refine the LLM’s
reasoning and decision-making capabilities, aiming to create
more adaptable and efficient human-robot teamwork beyond
warehouse-specific tasks.
REFERENCES
[1] A. Pathak and R. Muthusamy, “Collapse and collision aware
grasping for cluttered shelf picking,” 2025. [Online]. Available:
https://arxiv.org/abs/2503.22427
[2] Z. Zhao, J. Cheng, J. Liang, S. Liu, M. Zhou, and Y. Al-Turki,
“Order picking optimization in smart warehouses with human–robot
collaboration,” IEEE Internet of Things Journal, vol. 11, no. 9, pp.
16 314–16 324, 2024.
[3] A.
Pasparakis,
J.
de
Vries,
and
M.
de
Koster,
“In
control
or under control? human-robot collaboration in warehouse order
picking,”
SSRN
Electronic
Journal,
2021.
[Online].
Available:
https://api.semanticscholar.org/CorpusID:238001553
[4] F. Jacob, E. H. Grosse, S. Morana, and C. J. K¨onig, “Picking with
a robot colleague: A systematic literature review and evaluation of
technology acceptance in human–robot collaborative warehouses,”
Computers & Industrial Engineering, vol. 180, p. 109262, 2023.
[Online]. Available: https://www.sciencedirect.com/science/article/pii/
S0360835223002863
[5] T. Motoda, D. Petit, W. Wan, and K. Harada, “Bimanual shelf picking
planner based on collapse prediction,” in 2021 IEEE 17th International
Conference on Automation Science and Engineering (CASE), 2021, pp.
510–515.
[6] T. Motoda, D. Petit, T. Nishi, K. Nagata, W. Wan, and K. Harada,
“Multi-step object extraction planning from clutter based on support
relations,” IEEE Access, vol. PP, pp. 1–1, 01 2023.
[7] ——, “Shelf replenishment based on object arrangement detection
and collapse prediction for bimanual manipulation,” Robotics, vol. 11,
no. 5, 2022.
[8] Y.-L. Chen, Y.-R. Cai, and M.-Y. Cheng, “Vision-based robotic ob-
ject grasping—a deep reinforcement learning approach,” Machines,
vol. 11, no. 2, 2023.
[9] W. Bejjani, W. C. Agboh, M. R. Dogar, and M. Leonetti, “Occlusion-
aware search for object retrieval in clutter,” 2021. [Online]. Available:
https://arxiv.org/abs/2011.03334
[10] A. Zook, F.-Y. Sun, J. Spjut, V. Blukis, S. Birchfield, and J. Tremblay,
“Grs: Generating robotic simulation tasks from real-world images,”
2024.
[11] R. Ni and A. H. Qureshi, “Progressive learning for physics-informed
neural motion planning,” 2023.
[12] Z. Long, G. Killick, R. McCreadie, and G. A. Camarasa, “Robollm:
Robotic vision tasks grounded on multimodal large language models,”
2024.
[13] J. Bohg, A. Morales, T. Asfour, and D. Kragic, “Data-driven grasp
synthesis—a survey,” IEEE Transactions on Robotics, vol. 30, no. 2,
pp. 289–309, 2014.
[14] C. Banerjee, K. Nguyen, C. Fookes, and G. Karniadakis, “Physics-
informed computer vision: A review and perspectives,” 2024.
[15] H. Chen and I. Y. Chan, “A systematic literature review of trust-
aware shared control for human-robot collaboration in construction,”
in 2024 16th International Conference on Computer and Automation
Engineering (ICCAE), 2024, pp. 502–506.
[16] P. Khanna, E. Yadollahi, M. Bj¨orkman, I. Leite, and C. Smith,
“User study exploring the role of explanation of failures by robots
in human robot collaboration tasks,” 2023. [Online]. Available:
https://arxiv.org/abs/2303.16010
[17] A. Yang, B. Yang, B. Zhang, B. Hui, B. Zheng, B. Yu, C. Li, D. Liu,
F. Huang, H. Wei et al., “Qwen2. 5 technical report,” arXiv preprint
arXiv:2412.15115, 2024.
