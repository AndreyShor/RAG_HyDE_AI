SigChord: Sniffing Wide Non-sparse Multiband Signals for Terrestrial and Non-terrestrial Wireless Networks
MobiSys â€™25, June 23â€“27, 2025, Anaheim, California, US
ğ‘
ğ‘ƒ
â€¦
ğ‘
ğ¹
Prepend 
[CLS] token
Embedding 
process
Linear layer
Predict spectrum 
occupancy
Encoder layer
Encoder layer
Figure 6: The architecture for spectrum sensing.
sensing as a multi-label binary classification task to predict sub-
band occupancy. The true spectrum occupancy is represented by a
vector of length ğ¿, where the ğ‘—-th element indicates whether the
ğ‘—-th sub-band is occupied. The spectrum sensor, shown in Figure 6,
consists of two Transformer encoder layers and a linear layer. To
reduce complexity, a learnable [CLS] token of dimension ğ‘‘ğ‘šğ‘œğ‘‘ğ‘’ğ‘™
is prepended to the embedding, independent of the input. After
passing through the encoders, the hidden state of the [CLS] token
is fed to the linear layer, activated by Sigmoid to produce the output
Ë†ğ‘†âˆˆ(0, 1)ğ¿, where Ë†ğ‘†ğ‘—denotes the occupancy probability of the ğ‘—-th
sub-band.
After data-driven spectrum sensing, we use Ë†ğ‘†for rule-based
signal recovery. Ë†ğ‘†indicates the occupied sub-bands, i.e., the non-
zero rows of the spectrum matrix ğ‘‹. This enables identification
of the contributing rows of ğ‘‹and columns of ğ´in Eq. (1). Let
ğ‘†= {ğ‘—| Ë†ğ‘†ğ‘—> ğœƒ}, where ğœƒâˆˆ(0, 1) is the threshold. We select the
columns of ğ´and rows of ğ‘‹corresponding to ğ‘†, denoted as ğ´ğ‘†
and ğ‘‹ğ‘†. In the noise-free case, this gives ğ‘Œ= ğ´ğ‘†ğ‘‹ğ‘†. If |ğ‘†|< ğ‘ƒ, the
equation becomes overdetermined, and ğ‘‹ğ‘†can be solved via least
squares. Our recovery algorithm is presented Algorithm 1. Note
that the condition |ğ‘†|â‰¤ğ‘ƒaligns with the non-blind Landau rate.
With ğ‘ƒADCs sampling at ğµ/ğ¿, the total sampling rate is ğ‘ƒ
ğ¿ğµ, and
the total occupied bandwidth is |ğ‘†|
ğ¿ğµ. Hence, |ğ‘†| â‰¤ğ‘ƒsatisfies the
Landau rate limit.
The spectrum sensing and sub-band signal recovery granularity
of SigChord is ğµ/ğ¿, determined by the sampling rate of each low-
speed ADC in multi-coset sampling. To achieve finer granularity,
each single ADC can be logically treated as ğ‘˜alternating ADCs,
each sampling at ğµ/(ğ‘˜ğ¿). By reorganizing the measurement matrix
ğ´and resultsğ‘Œ, this refinement could enhance granularity to ğµ/(ğ‘˜ğ¿)
without hardware modifications.
3.3
Protocol Identification
This model identifies the protocol in each sub-band and forwards
signal frames with intact headers to the header decoding model, fil-
tering out those without. Let ğ‘‹ğ‘†âˆˆC|ğ‘†|Ã—ğ‘represent the frequency-
domain signals in the selected sub-bands. Each row of ğ‘‹ğ‘†under-
goes an inverse Fourier transform to the time domain, denoted
as ğ‘¥(ğ‘—)
ğ‘ğ‘âˆˆC1Ã—ğ‘, ğ‘—= 1, 2, . . . , |ğ‘†|, which are then processed in par-
allel by the protocol identification model. Structurally, each ğ‘¥(ğ‘—)
ğ‘ğ‘
Algorithm 1: Transformer-based sub-Nyquist signal re-
covery
Input: multi-coset samples ğ‘¦âˆˆCğ‘ƒÃ—ğ‘, measurement matrix
ğ´âˆˆCğ‘ƒÃ—ğ¿, the spectrum sensing model
ğ‘“: Cğ‘ƒÃ—ğ‘â†’(0, 1)ğ¿, threshold ğœƒâˆˆ(0, 1).
Output: spectrum matrix ğ‘‹ğ‘†for the occupied sub-bands.
Require: |{ğ‘—| Ë†ğ‘†ğ‘—> 0}| â‰¤ğ‘ƒ.
1 Predict occupied sub-bands Ë†ğ‘†â†ğ‘“(ğ‘¦) ;
2 Predict the support set ğ‘†â†{ğ‘—| Ë†ğ‘†ğ‘—> ğœƒ} ;
3 Select columns of ğ´corresponding to ğ‘†as ğ´ğ‘†;
4 Transform ğ‘¦to the measurement result ğ‘Œ;
5 Solve ğ‘‹ğ‘†â†arg min Ëœğ‘‹âˆ¥ğ‘Œâˆ’ğ´ğ‘†Ëœğ‘‹âˆ¥2.
ğ‘
1
â€¦
ğ‘
ğ¹
Query token
Embedding 
process
Linear layers
Recovered signal 
on sub-bands
Identify protocol
To header decoder
Encoder layer
Encoder layer
Decoder layer
Figure 7: The architecture for protocol identification.
can be treated as an extreme case of multi-coset sampling with
only one low-speed ADC. This allows the preprocessing steps from
Section 3.1 to be applied directly, where ğ‘ƒ= 1 in this case. The
protocol identification model is illustrated in Figure 7. In addition to
its classification role, this model also functions as a feature extrac-
tor for the subsequent header decoding model, which is primarily
based on decoder layers. To enable effective feature sharing with
the header decoding model, we use a combination of Transformer
encoder and decoder layers rather than an encoder-only structure
as in the spectrum sensor. The model processes the embedded ğ‘¥(ğ‘—)
ğ‘ğ‘
features through two encoder layers and correlates them with a
learnable query token as a substitute for the [CLS] token. This
query token is unrelated to the input and serves as a part of the
modelâ€™s learnable parameters. The decoder layer applies attention
mechanism between the query token and encoder output to ex-
tract global signal features, which are then classified via two linear
layers. The dimension of the hidden linear layer is set to ğ‘‘ğ‘šğ‘œğ‘‘ğ‘’ğ‘™
with GELU activation, layer normalization and a dropout rate of 0.1.
The output from the final linear layer is activated by Softmax. To
account for signal frames in sub-bands lacking intact headers and
therefore undecodable, a dedicated no-header class is included in
the classification. Additionally, the encoder features are forwarded
to the header decoding model for feature fusion.
3.4
Header Decoding
This module is responsible for decoding signal frames with intact
protocol headers to retrieve open fields from the physical layer
