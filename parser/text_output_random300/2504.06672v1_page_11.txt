[41] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Am-
non Shashua, Kevin Leyton-Brown, and Yoav Shoham. In-
Context Retrieval-Augmented Language Models. Transac-
tions of the Association for Computational Linguistics, 11:
1316–1331, 2023. 1, 3
[42] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Patrick Esser, and Bj¨orn Ommer.
High-resolution image
synthesis with latent diffusion models.
In Proceedings of
the IEEE/CVF conference on computer vision and pattern
recognition, pages 10684–10695, 2022. 2, 3
[43] Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch,
Michael Rubinstein, and Kfir Aberman. Dreambooth: Fine
tuning text-to-image diffusion models for subject-driven
generation.
In Proceedings of the IEEE/CVF conference
on computer vision and pattern recognition, pages 22500–
22510, 2023. 3
[44] Shelly Sheynin, Oron Ashual, Adam Polyak, Uriel Singer,
Oran Gafni, Eliya Nachmani, and Yaniv Taigman.
Knn-
diffusion: Image generation via large-scale retrieval. arXiv
preprint arXiv:2204.02849, 2022. 3
[45] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An,
Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual,
Oran Gafni, et al. Make-a-video: Text-to-video generation
without text-video data. arXiv preprint, 2022. 2
[46] Jiaming
Song,
Chenlin
Meng,
and
Stefano
Ermon.
Denoising diffusion implicit models.
arXiv preprint
arXiv:2010.02502, 2020. 3, 6
[47] Spencer Sterling. Zeroscope, 2023. 5, 6
[48] Hung-Yu Tseng, Hsin-Ying Lee, Lu Jiang, Ming-Hsuan
Yang, and Weilong Yang. Retrievegan: Image synthesis via
differentiable patch retrieval.
In Computer Vision–ECCV
2020: 16th European Conference, Glasgow, UK, August
23–28, 2020, Proceedings, Part VIII 16, pages 242–257.
Springer, 2020. 3
[49] Thomas Unterthiner, Sjoerd Van Steenkiste, Karol Kurach,
Raphael Marinier, Marcin Michalski, and Sylvain Gelly. To-
wards accurate generative models of video: A new metric &
challenges. arXiv preprint arXiv:1812.01717, 2018. 6
[50] Jiuniu Wang, Hangjie Yuan, Dayou Chen, Yingya Zhang,
Xiang Wang, and Shiwei Zhang. Modelscope text-to-video
technical report. arXiv preprint arXiv:2308.06571, 2023. 2,
3
[51] Mengmeng Wang, Jiazheng Xing, and Yong Liu. Actionclip:
A new paradigm for video action recognition. arXiv preprint
arXiv:2109.08472, 2021. 4
[52] Xiang Wang, Hangjie Yuan, Shiwei Zhang, Dayou Chen, Ji-
uniu Wang, Yingya Zhang, Yujun Shen, Deli Zhao, and Jin-
gren Zhou. Videocomposer: Compositional video synthesis
with motion controllability. arXiv preprint, 2023. 3
[53] Yaohui Wang, Xinyuan Chen, Xin Ma, Shangchen Zhou,
Ziqi Huang, Yi Wang, Ceyuan Yang, Yinan He, Jiashuo
Yu, Peiqing Yang, et al. Lavie: High-quality video gener-
ation with cascaded latent diffusion models. arXiv preprint
arXiv:2309.15103, 2023. 2, 3
[54] Jay Zhangjie Wu, Yixiao Ge, Xintao Wang, Stan Weixian
Lei, Yuchao Gu, Yufei Shi, Wynne Hsu, Ying Shan, Xiaohu
Qie, and Mike Zheng Shou. Tune-a-video: One-shot tuning
of image diffusion models for text-to-video generation. In
ICCV, 2023. 2
[55] Tianxing Wu, Chenyang Si, Yuming Jiang, Ziqi Huang, and
Ziwei Liu. Freeinit: Bridging initialization gap in video dif-
fusion models. arXiv preprint arXiv:2312.07537, 2023. 2, 5,
6
[56] Katherine Xu, Lingzhi Zhang, and Jianbo Shi. Good seed
makes a good crop: Discovering secret seeds in text-to-
image diffusion models. arXiv preprint arXiv:2405.14828,
2024. 5
[57] Ling Yang, Zhaochen Yu, Chenlin Meng, Minkai Xu, Ste-
fano Ermon, and CUI Bin.
Mastering text-to-image dif-
fusion: Recaptioning, planning, and generating with multi-
modal llms. In Forty-first International Conference on Ma-
chine Learning, 2024. 3
[58] Shuai Yang, Yifan Zhou, Ziwei Liu, and Chen Change
Loy. Rerender a video: Zero-shot text-guided video-to-video
translation. In SIGGRAPH Asia 2023 Conference Papers,
2023. 1, 2
[59] Danah Yatim, Rafail Fridman, Omer Bar-Tal, Yoni Kasten,
and Tali Dekel. Space-time diffusion features for zero-shot
text-driven motion transfer. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition
(CVPR), pages 8466–8476, 2024. 3
[60] Rui Zhao, Yuchao Gu, Jay Zhangjie Wu, David Jun-
hao Zhang, Jia-Wei Liu, Weijia Wu, Jussi Keppo, and
Mike Zheng Shou. Motiondirector: Motion customization
of text-to-video diffusion models. In European Conference
on Computer Vision, pages 273–290. Springer, 2024. 3, 2
[61] Zangwei Zheng, Xiangyu Peng, Tianji Yang, Chenhui Shen,
Shenggui Li, Hongxin Liu, Yukun Zhou, Tianyi Li, and Yang
You. Open-sora: Democratizing efficient video production
for all, 2024. 1, 2
11
