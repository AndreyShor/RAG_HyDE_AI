Environment
Horizon
DreamerV3-e
DreamerV3-r
MoSim-e
MoSim-r
MoSim-rm
1-step
5-step
1-step
5-step
Cheetah
16
8.2538
6.5270
0.8747
0.1925
0.5342
0.1206
/
100
6.5507
5.8468
0.4048
0.2297
1.1876
0.2185
/
Reacher
16
0.7370
0.1081
0.7451
0.0972
0.0037
0.0005
/
100
0.7405
0.1743
0.7532
0.0988
0.0053
0.0009
/
Acrobot
16
3.6390
0.9356
3.7423
0.1015
/
0.0001
/
100
9.7392
4.8957
9.7547
4.9276
/
0.1043
/
Panda
16
/
/
0.2396
0.0434
/
0.0010
/
100
/
/
0.3367
0.0971
/
0.0043
/
Hopper
16
/
/
0.6406
0.1114
/
0.0743
0.0375
100
/
/
0.9239
0.3199
/
0.4049
0.2507
Go2
16
/
/
1.0097
0.3685
/
0.0430
0.0410
100
/
/
0.9243
0.4165
/
0.1282
0.1401
Humanoid
5
/
/
5.2171
1.3947
/
0.9382
0.6535
10
/
/
6.0500
1.8263
/
1.5344
1.0063
16
/
/
6.5078
2.1291
/
1.9735
1.2737
Table 1. MoSim versus DreamerV3. Evaluated on random policy datasets. Easy tasks. The suffix ‘-e’ denotes models trained on experience
data from Dreamer’s replay buffer, ‘-r’ indicates models trained on random policy data, and ‘-rm’ refers to MoSim trained on random policy
data with the multistage approach.
Environment
Horizon
DreamerV3-e
DreamerV3-r
MoSim-e
MoSim-r
1-step
5-step
1-step
5-step
Cheetah
16
13.1264
4.8908
18.4404
11.1325
3.8841
5.6052
100
13.8990
9.4270
18.6197
4.5623
13.0104
3.8434
Reacher
16
0.3430
0.0514
0.4670
0.04875
0.0027
0.0005
100
0.3562
0.0803
0.4364
0.05712
0.0030
0.0008
Acrobot
16
5.0681
1.3900
5.0681
1.3900
/
0.0121
100
16.8498
11.1576
16.8498
11.1576
/
1.2864
Table 2. MoSim versus DreamerV3. Evaluated on the TD-MPC2 policy dataset, which means the evaluation data is out-of-distribution
(OOD) for all models. The results show that models trained on random datasets (-r) generally achieve lower prediction errors than model
trained on experience datasets (-e), indicating a stronger generalization capability.
Environment
TD-MPC2-e
MoSim-e
Humanoid
0.00011
0.00009
Cheetah
0.0009
0.0007
Reacher
4.8101e-5
2.9256e-7
Table 3. MoSim versus TD-MPC2. Evaluated on TD-MPC policy
datasets.
3. In all environments, we performed three-step predictions,
following the default prediction steps of TD-MPC2. We
also do the comparison for random data in table 4.
Environment
TD-MPC2-e
MoSim-rm
Humanoid
0.0050
0.0020
Cheetah
0.0011
0.0003
Reacher
9.9229e-5
7.0000e-7
Table 4. MoSim versus TD-MPC2. Evaluated on random datasets.
3.3. Stochasticity
While MoSim assumes deterministic dynamics, we exam-
ine its robustness to observation noise and its capability to
reliably sample multiple future trajectories.
Table 5 shows that MoSim remains robust to noise in
5
